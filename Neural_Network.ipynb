{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aryan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/aryan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/aryan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/aryan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/aryan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/aryan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/aryan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/aryan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/aryan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/aryan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/aryan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/aryan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_function = sigmoid\n",
    "from scipy.stats import truncnorm\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm((low - mean) / sd, \n",
    "                     (upp - mean) / sd, \n",
    "                     loc=mean, \n",
    "                     scale=sd)\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,innode,outnode,hidnode,learning_rate):\n",
    "        self.innode = innode\n",
    "        self.outnode= outnode\n",
    "        self.hidnode = hidnode\n",
    "        self.learning_rate = learning_rate \n",
    "        self.create_weight_matrices()\n",
    "        \n",
    "    def create_weight_matrices(self):\n",
    "        rad = 1 / np.sqrt(self.innode)\n",
    "        X = truncated_normal(mean=0,sd=1,low=-rad,upp=rad)\n",
    "        self.wih = X.rvs((self.hidnode,self.innode))\n",
    "        rad = 1 / np.sqrt(self.hidnode)\n",
    "        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n",
    "        self.who = X.rvs((self.outnode,self.hidnode))\n",
    "        \n",
    "    \n",
    "    def train(self, input_vector, target_vector):\n",
    "        input_vector = input_vector/255.0\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "        \n",
    "        output_vector1 = np.dot(self.wih,input_vector)\n",
    "        output_hidden = activation_function(output_vector1)\n",
    "        \n",
    "        output_vector2 = np.dot(self.who,output_hidden)\n",
    "        output_network = activation_function(output_vector2)\n",
    "        \n",
    "        output_errors = target_vector - output_network\n",
    "        tmp = output_errors * output_network \\\n",
    "              * (1.0 - output_network)     \n",
    "        tmp = self.learning_rate  * np.dot(tmp,output_hidden.T)\n",
    "        self.who += tmp\n",
    "        hidden_errors = np.dot(self.who.T,output_errors)\n",
    "        tmp = hidden_errors * output_hidden * (1.0 - output_hidden)\n",
    "        self.wih += self.learning_rate * np.dot(tmp, input_vector.T)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def run(self, input_vector):\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        output_vector = np.dot(self.wih,input_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        \n",
    "        output_vector = np.dot(self.who,output_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "    \n",
    "        return output_vector\n",
    "            \n",
    "    def confusion_matrix(self, data_array, labels):\n",
    "        cm = np.zeros((10, 10), int)\n",
    "        for i in range(len(data_array)):\n",
    "            res = self.run(data_array[i])\n",
    "            res_max = res.argmax()\n",
    "            target = labels[i][0]\n",
    "            cm[res_max, int(target)] += 1\n",
    "        return cm    \n",
    "    def precision(self, label, confusion_matrix):\n",
    "        col = confusion_matrix[:, label]\n",
    "        return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "    def recall(self, label, confusion_matrix):\n",
    "        row = confusion_matrix[label, :]\n",
    "        return confusion_matrix[label, label] / row.sum()\n",
    "        \n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        corrects, wrongs = 0, 0\n",
    "        for i in range(len(data)):\n",
    "            res = self.run(data[i])\n",
    "            res_max = res.argmax()\n",
    "            if res_max == labels[i]:\n",
    "                corrects += 1\n",
    "            else:\n",
    "                wrongs += 1\n",
    "        return corrects, wrongs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807970779778823"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_function(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ANN = NeuralNetwork(innode = 784, \n",
    "                    outnode = 10, \n",
    "                    hidnode = 100,\n",
    "                    learning_rate = 0.1)\n",
    "    \n",
    "    \n",
    "for i in range(len(x)):\n",
    "    ANN.train(x[i], y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] 5\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 0\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 4\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] 9\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] 2\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] 3\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 4\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] 3\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] 5\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] 3\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] 6\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] 7\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] 2\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] 8\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] 6\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in power\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(20):\n",
    "    res = ANN.run(x[i])\n",
    "    print(y[i],np.argmax(res))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in power\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 228 6755    0    0    0    0    0    0    0    0]\n",
      " [7931    0    0    0    0    0    0    0    0    0]\n",
      " [7173   18    0    0    0    0    0    0    0    0]\n",
      " [6889    7    0    0    0    0    0    0    0    0]\n",
      " [6831    9    0    0    0    0    0    0    0    0]\n",
      " [6378   22    0    0    0    0    0    0    0    0]\n",
      " [6762   37    0    0    0    0    0    0    0    0]\n",
      " [7275    5    0    0    0    0    0    0    0    0]\n",
      " [6853   47    0    0    0    0    0    0    0    0]\n",
      " [6777    3    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(ANN.confusion_matrix(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
